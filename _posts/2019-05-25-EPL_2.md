---
title: "Predicting Whether Football Games Are Worth Watching Part 2"
date: 2019-05-21
tags: [projects, machine learning, analytics, classification, python]
mathjax: true
classes: wide
---

[The first post in this should be read before this one](http://sjhatfield.github.io/EPL_1)

## A Reminder Of The Stage We Are At

The problem at hand is to predict whether English Premier League games will be exciting to watch before they have taken place. The data that is being used to predict this is goals (for and against), yellow cards and shots on target, from the games that have taken place in the season already. The end goal is to be able to tell the user (aka me) which game in the coming weekend of football is the most likely to be exciting to watch.

## A Disclaimer About This Post

I am going to tell you right now that the approaches used in this post are not going to be successful. In my years as a mathematics teacher, one of the most challenging parts has been creating an environment in my classroom where students are comfortable to put forward ideas, no matter whether they are definitely correct or not. In this post, I'm following my own advice and putting forward an idea, following it through to completion, only to find it doesn't work and isn't appropriate. This was a valuable learning experience for myself and I think is worth discussing why the logistic regression doesn't work.

## The Idea Behind Logistic Regression

To view the code used to perform the regression and read a more in-depth explanation of the matheamtics involved, please follow the link to the notebook TODODODODOD

Most people have seen *linear* regression in a statistics class at some point in their lives. The purpose of *linear* regression is to predict the value of a dependent variable based on the value of a independent one using data that has been collected. For example trying to predict the length of a lobster based on the quality of the water it lives in. To do this, a regression equation is found which minimizes the distance from the line to each of the independent/dependent pairs in the data.

*Logistic* regression is for the situation where we want to predict a binary outcome[^1] based on the independent data. For example whether a student will pass or fail an exam based on the hours of study they spent studying. Linear regression is not appropriate in this case as the plot of this situation would looks something like this:

<img src="{{ site.url }}{{ site.baseurl }}/images/EPL2/PassFail.png" alt="Plot of time studying for an exam versus whether the student passed or failed">

Rather, we need a model that can take in the independent variables and give out a prediciton of which class the dependent variable will be in. We would expect a good model of the data above to predict a student who has spent 2 hours to studying to fail and a student who has spent 18 hours to pass. There will be a critical value somewhere between 8 and 12.5 hours where the model switches its prediction.

The output of a logistic regression for a given set of predictors will be the probability of the outcome being a pass. You can then categorise all outcomes with a probability over 0.5 as predicting a pass and the others as fails. This is the critical point described above.

This seems like a good approach to my football prediction problem as we can fit a logistic regression to my data and then get probabilities for future games being exciting to watch and simply watch the one with highest probability.

## The Reality After Using The Model

I implemented the model myself using the usual suspects (Pandas and NumPy), fit it to a training set and evaluated on the remaining testing set. Notebook link here #TODODODODO

Initially, there were promising results. My implementation gave regression coefficients for each of the predictors of:

* Home Goals Scored: 0.0505
* Home Goals Against: -0.0614
* Home Yellow Cards: 0.0444
* Home Red Cards: 0.1467
* Home Worth Watching: 0.5070
* Away Goals Scored: 0.0147
* Away Goals Against: -0.0674
* Away Yellow Cards: -0.0370
* Away Red Cards: 0.0971
* Away Worth Watching: 0.4438
* Intercept: -0.9334

The predictors with positive coefficients can be interpretted as having a positive effect on the chance of a game being worth watching. For example a home team having a high proportion of past games worthing watching is going to increase the probability that the logistic regression is going to tell us ot watch the game. Therefore, it makes sense that goals scored and worth watching are positive with worth watching having the greatest impact. Surely, if two teams are playing and they both have a high proportion of their past games being excited they are likely to have an exciting game.

Goals against is a bit trickier to interpret as a games excitement is linked to the number of goals that occur in the game. If a team concedes a lot of goals then their games should have a good chance of being exciting. But what if they hardly score any themselves and usually just lose 1-0 or 2-0? Their games are not considered as exciting in my model. The 'goals against' coefficients are both negative and close to zero meaning they don't impact the prediction nearly as much as the worth watching predictors.

In fact, the "Home Worth Watching", "Away Worth Watching" and intercept coefficients have the greatest influence on the outcome of the model. It begs the question, should we just predict based on whether teams are usually worth watching?

But first, lets see how this logistic regression performed on the test data. To find out the probabilities associated with each test game we multiply the regression coefficients by the game data and apply the sigmoid function[^2]. This was done and some sample results were shown using

```python
scores = test.drop('watch', axis=1) @ theta
predictions = sigmoid(scores)
predictions.sample(20)
```
with an output of 

<img src="{{ site.url }}{{ site.baseurl }}/images/EPL2/results.png" alt="Sample probability resutls from the logistic regression model">

The values in the first column are indices of the dataframe and the second column is the probability of the game being worth watching. Unfortunately, almost all the probabilities are between 0.25 and 0.5. Usually, we would classify anything over 0.5 as a 1 and 0 otherwise. If we did that, the model would only predict one single game as worth watching.

The correctness of my implementation of the logistic regression was checked using Scikit-Learn and very close coefficients of the regression equation were found. For the Schikit-Learn generated model, a confusion matrix was created and the following accuracy numbers were found:

* True negatives: 825
* True positives: 1
* False positives: 1
* False negatives: 423

The model having one false positive is very surprising given it has only predicted 2 games to be worth watching. The clear issue here is the huge number of false negatives. These were games worth watching which the model failed to predict.

What if we set a lower percentage as the boundary between predicting to watch or not? I set the cut off to a probability of 0.35 using

```python
alt_results = pd.DataFrame(data={'probs': probs, 'original': test['watch']})
alt_results['preds'] = results['probs'].apply(lambda x: 1 if x > 0.35 else 0)
print(confusion_matrix(alt_results['original'],alt_results['preds']))
print((alt_results['original'] == alt_results['preds']).sum())
```

the values in the confusion matrix were:

* True negatives: 616
* True positives: 139
* False positives: 285
* False negatives: 210

so in this case, if the model tells you to watch a game, you have a $$\frac{139}{424} = 32.8\%$$ chance of it actually worth watching. Which is not ideal as 33% of games are worth watching anyway.

[^1]: Logistic regression can be generalized to more than two possible outcomes using [multinomial logistic regression](https://www.wikiwand.com/en/Multinomial_logistic_regression).

[^2]: This is explained in far more depth in the notebook LINK #TODODODODODODODODODO.

