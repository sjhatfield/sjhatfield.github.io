---
title: "Predicting Whether Football Games Are Worth Watching Part 2"
date: 2019-05-21
tags: [projects, machine learning, classification, python, R]
mathjax: true
classes: wide
---

[The first post in this should be read before this one](http://sjhatfield.github.io/EPL_1)

## A Reminder Of The Stage We Are At

The problem at hand is to predict whether English Premier League games will be exciting to watch before they have taken place. The data that is being used to predict this is goals (for and against), yellow cards and shots on target, from the games that have taken place in the season already. The end goal is to be able to tell the user (aka me) which game in the coming weekend of football is the most likely to be exciting to watch.

## A Disclaimer About This Post

I am going to tell you right now that the approaches used in this post are not going to be successful. In my years as a mathematics teacher, one of the most challenging parts has been creating an environment in my classroom where students are comfortable to put forward ideas, no matter whether they are definitely correct or not. In this post, I'm following my own advice and putting forward an idea, following it through to completion, only to find it doesn't work and isn't appropriate. This was a valuable learning experience for myself and I think is worth discussing why the logistic regression doesn't work.

## The Idea Behind Logistic Regression

To view the code used to perform the regression and read a more in-depth explanation of the matheamtics involved, please follow the link to the notebook TODODODODOD

Most people have seen *linear* regression in a statistics class at some point in their lives. The purpose of *linear* regression is to predict the value of a dependent variable based on the value of a independent one using data that has been collected. For example trying to predict the length of a lobster based on the quality of the water it lives in. To do this, a regression equation is found which minimizes the distance from the line to each of the independent/dependent pairs in the data.

*Logistic* regression is for the situation where we want to predict a binary outcome[^1] based on the independent data. For example whether a student will pass or fail an exam based on the hours of study they spent studying. Linear regression is not appropriate in this case as the plot of this situation would looks something like this:

<img src="{{ site.url }}{{ site.baseurl }}/images/EPL2/PassFail.png" alt="Plot of time studying for an exam versus whether the student passed or failed">

Rather, we need a model that can take in the independent variables and give out a prediciton of which class the dependent variable will be in. We would expect a good model of the data above to predict a student who has spent 2 hours to studying to fail and a student who has spent 18 hours to pass. There will be a critical value somewhere between 8 and 12.5 hours where the model switches its prediction.

The output of a logistic regression for a given set of predictors will be the probability of the outcome being a pass. You can then categorise all outcomes with a probability over 0.5 as predicting a pass and the others as fails. This is the critical point described above.

This seems like a good approach to my football prediction problem as we can fit a logistic regression to my data and then get probabilities for future games being exciting to watch and simply watch the one with highest probability.

## The Reality After Using The Model

I implemented the model myself using the usual suspects (Pandas and NumPy), fit it to a training set and evaluated on the remaining testing set. Notebook link here #TODODODODO

Initially, there were promising results. My implementation gave regression coefficients for each of the predictors of:

* Home Goals Scored: 0.0505
* Home Goals Against: -0.0614
* Home Yellow Cards: 0.0444
* Home Red Cards: 0.1467
* Home Worth Watching: 0.5070
* Away Goals Scored: 0.0147
* Away Goals Against: -0.0674
* Away Yellow Cards: -0.0370
* Away Red Cards: 0.0971
* Away Worth Watching: 0.4438
* Intercept: -0.9334

The predictors with positive coefficients can be interpretted as having a positive effect on the chance of a game being worth watching. For example a home team having a high proportion of past games worthing watching is going to increase the probability that the logistic regression is going to tell us ot watch the game. Therefore, it makes sense that goals scored and worth watching are positive with worth watching having the greatest impact. Surely, if two teams are playing and they both have a high proportion of their past games being excited they are likely to have an exciting game.

Goals against is a bit trickier to interpret as a games excitement is linked to the number of goals that occur in the game. If a team concedes a lot of goals then their games should have a good chance of being exciting. But what if they hardly score any themselves and usually just lose 1-0 or 2-0? Their games are not considered as exciting in my model. The 'goals against' coefficients are both negative and close to zero meaning they don't impact the prediction nearly as much as the worth watching predictors.

In fact, the "Home Worth Watching", "Away Worth Watching" and intercept coefficients have the greatest influence on the outcome of the model. It begs the question, should we just predict based on whether teams are usually worth watching?

But first, lets see how this logistic regression performed on the test data. To find out the probabilities associated with each test game we multiply the regression coefficients by the game data and apply the sigmoid function[^2]. This was done and some sample results were shown using

```python
scores = test.drop('watch', axis=1) @ theta
predictions = sigmoid(scores)
predictions.sample(20)
```
with an output of 

<img src="{{ site.url }}{{ site.baseurl }}/images/EPL2/results.png" alt="Sample probability resutls from the logistic regression model">

The values in the first column are indices of the dataframe and the second column is the probability of the game being worth watching. Unfortunately, almost all the probabilities are between 0.25 and 0.5. Usually, we would classify anything over 0.5 as a 1 and 0 otherwise. If we did that, the model would only predict one single game as worth watching.

The correctness of my implementation of the logistic regression was checked using Scikit-Learn and very close coefficients of the regression equation were found. For the Scikit-Learn generated model, a confusion matrix was created and the following accuracy numbers were found:

* True negatives: 825
* True positives: 1
* False positives: 1
* False negatives: 423

The model having one false positive is very surprising given it has only predicted 2 games to be worth watching. The clear issue here is the huge number of false negatives. These were games worth watching which the model failed to predict.

What if we set a lower percentage as the boundary between predicting to watch or not? I set the cut off to a probability of 0.35 using

```python
alt_results = pd.DataFrame(data={'probs': probs, 'original': test['watch']})
alt_results['preds'] = results['probs'].apply(lambda x: 1 if x > 0.35 else 0)
print(confusion_matrix(alt_results['original'],alt_results['preds']))
print((alt_results['original'] == alt_results['preds']).sum())
```

the values in the confusion matrix were:

* True negatives: 616
* True positives: 139
* False positives: 285
* False negatives: 210

so in this case, if the model tells you to watch a game, you have a $$\frac{139}{424} = 32.8\%$$ chance of it actually worth watching. Which is not ideal as 33% of games are worth watching anyway. So random selection would do slightly better.

## Why Did Logistic Regression Not Work?

There are many possible reasons that the logistic regression is a poor predictor for his data.

### The observation of predictor and label pairs are not independent

Let me take a step back first and define those terms. We are talking about the observation of each individual row of the data. Independent means that the fact I have observed one row of the data does not impact the probability of observing another. This should ring some alarm bells. If we consider the 3rd game of the season for a certain team, say Arsenal. Let's suppose that we have seen their 2nd game of the season in the data and it was worth watching with a final score of 6-4, with many shots on target and lots of yellow cards. This fact is going to influence the probability of seeing a certain outcome in the data for their 3rd game of the season because columns in the data are running totals of the current season. This independence of the predictor  label pairs in the data is one of the assumptions of a logistic regression model and is used in the derivation of the formulas used to find the regression coefficients.

### There Exists Collinearity Between The Predictor Variables

Let's define collinearity in statistcs. Two variables exhibit collinearity if there exists a linear relationship between them. Two varables $$X_1$$ and $$X_2$$ would exhibit perfect collinearity if there were parameters $$\lambda_1$$ and $$\lambda_2$$ such that

$$X_2 = \lambda_1 X_1 + \lambda_2$$

Multicollinearity is also possible where there is a linear relationship between multiple variables and one other. This is a problem when performing regression because collinearity between predictor variables means it is impossible to distinguish between the effects different variables are having on a prediction. To give an extreme example, consider the case where $$X$$ and $$Y$$ are being used to predict $$Z$$ where $$X$$ and $$Y$$ are perfectly correlated. Then the two models $$Z = a_0 + a_1X + a_2Y + e$$ and $$Z = a_0 + (a_1 + a_2)X + 0Y + e$$ would indistinguishable. Depsite being very different. [For more discussion follow this link](https://stats.stackexchange.com/questions/1149/is-there-an-intuitive-explanation-why-multicollinearity-is-a-problem-in-linear-r).

To test for collinearity between variables we can check the Variance Inflation Factor (VIF). We calculate it by fitting a linear regression for one of the predictor variables against all the others. Then $$VIF = \frac{1}{1 - R^2}$$ where $$R^2$$ is the usual correlation coefficient measure. Values above 2.5 indicate there is a need to worry about collinearity. I quickly did this check by loading the data in R and using the `vif` function of the `usdm` library. Here is the code that performed the check:

```r
library(usdm) # This library must be installed
df <- read.csv(file = 'clean_data.csv', header = T) # Load csv file into a dataframe
df <- df[,c('HGS','HGA','HYC','HWW','AGS','AGA','AYC','AWW')] # Only keep the necessary columns
vif(df) # Use the VIF function of the usdm library
```

The VIF output values were:
Variables   VIF
HGS         2.249040

HGA         2.268226

HYC         1.021158

HWW         2.563035

AGS         2.249001

AGA         2.135894

AYC         1.033712

AWW         2.528631

The two variables that are being flagged are 'HWW' and 'AWW'. These are exhibiting collinearity with the other variables. However, this actually makes sense and I think is desirable. The number of goals a team scores, the shots on target they have and number of cards is should correlate with the proportion of games that are worth watching.

This is pointing me towards the idea, that I should predict whether a game will be worth watching solely based on the proportion of previous games that the home and away team have had worth watching. In other words, **I should fit the model only with 'HWW' and 'AWW'**. This process of eliminating variables from a model is called **subset extraction**. Please see the [notebook](#TODODOD) for more details on how this was done.

Sadly, the performance was still relatively poor with just these two predictors. We saw a slight improvement in the classification with the confusion matrix values being:

* True negatives: 616
* True positives: 139
* False positives: 285
* False negatives: 210

[^1]: Logistic regression can be generalized to more than two possible outcomes using [multinomial logistic regression](https://www.wikiwand.com/en/Multinomial_logistic_regression).

[^2]: This is explained in far more depth in the notebook LINK #TODODODODODODODODODO.
