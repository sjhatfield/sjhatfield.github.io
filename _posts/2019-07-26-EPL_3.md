---
title: "Predicting Whether Football Games Are Worth Watching Part 3"
date: 2019-07-26
tags: [projects, machine learning, classification, python]
mathjax: true
classes: wide
---

[Here is a link to part 2](http://sjhatfield.github.io/EPL_2) and [here is a link to part 1](http://sjhatfield.github.io/EPL_1)

## A Reminder Of The Problem

The problem at hand is to predict whether English Premier League games will be exciting to watch before they have taken place. The data that is being used to predict this is goals (for and against), yellow cards and shots on target, from the games that have taken place in the season already. The end goal is to be able to tell the user (aka me) which game in the coming weekend of football is the most likely to be exciting to watch.

## Generating Another Variable

Previously, we only used previous game statistics such as goals scored, yellow cards etc to predict whether future games between two teams will be worth watching. The models used have performed slightly better than random guessing. It is clear that I need to try something else. In the original dataset betting odds were also included so I am going to try using those also. These will be available before a game takes place so may be used for prediction.

I am also going to try using the placement in the Premiership League table. A team's placement in the Premiership League table is determined by the number of points they have. I was able to use all previous fixtures from the current season to populate a dictionary of points for each team. Then I added two columns to the data, `HP` (home points) and `AP` (away points). You can see how I did this by checking out the [Jupyter Notebook](https://github.com/sjhatfield/worthwatching/blob/master/Team_Points.ipynb).

## Addressing Collinearity Issues

In [part 2](http://sjhatfield.github.io/EPL_2) of this series collinearity between variables was identified as an issue which was limiting model predicitons. To eliviate this I am going to remove all the previous game statistics, except for `HWW` and `AWW`. Reminder: `HWW` and `AWW` are the proportion of previous games in the season that have been worth watching for the Home and Away team who are to play. These variables are calculated based of the others (goals scored, shots on target etc) so it makes sense that only these should be used. If we think about how these two values would be expected to influence the worth watching prediction for a game, it would make sense that if both these are low, we would expect a game to have a low chance of being worth watching. On the other hand, if two teams have a high value for each we would expect the game to have a higher chance of being worth watching. With this in mind, I decided to combine these two variables into a single one by adding them together.

## The Betting Variable

All previous seasons had odds available for a home win, draw and away win from the well-established gambling company *William Hill*. When making future predictions, I will be able to find these odds easily online and be able to update predictions as the odds change, in the run up to a week of games. If we again think about issues around collinearity, or of variables influencing one another, then the odds for a home or away win should ring alarm bells. It is clear that as odds for a home win increase, the odds for an away win should decrease (otherwise the betting company wouldn't be very successful!).  My instinct says that if the odds of a home and away win are similar the game should be worth watching. If the home team are given high odds of winning (and the away team low) then a 2-0 win to the home team is fairly likely which won't be an exciting game.

With that in mind I have decided to combine those using 

$$BD = \frac{1}{|HO - AO|}$$

where $$BD$$ is betting difference, $$HO$$ is home odds and $$AO$$ is away odds. One issue is that if the odds are equal, this equation gives infinity so I had to put in this line of code:

```python
data['betting diff'] = data['betting diff'].apply(lambda x: x if x != np.inf else 0.01)
```

where 0.01 is a number chosen close to zero. It was chosen because it is lower than any other value given by the formula.

## Assessing A Models Performance

Before trying different models with the new variables I thought about how I want to assess the models performance. I identified the ideal outcome of this project earlier to be: a prediction of which game in the upcoming week (usually weekend) will be most likely to be worth watching. So far, I have not really assessing my models on this basis. I have simply looked at whether the model can predict whether individual games will be worth watching. Rather, I am going to look at the data in chunks per week, and ask the model to pick the game most likely to be worth watching. Then if the model identified a game that was worth watching, remembering there could be multiple in a week(end), I will consider it a success on that week. This means yet more data manipulation which I am learning does make up a large proportion of a Data Scientists time.

## New Models

As I have learnt more about machine learning, I have come across more and more models for classification. I decided to try decision trees, random forests and support vector machines for this project. I will give a quick overview of each.

## Decision Tree Models

A decision tree model makes decisions by asking a series of binary questions and makes a classification based on the answers. It is called a tree because it has the appearance of a tree from computer science. I have created a simple example below based on classifying cars as good or bad value.

[^1]: I have already tried k-Nearest Neighbors and Logistic Regression in older posts.